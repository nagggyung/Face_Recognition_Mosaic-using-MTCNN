{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10270839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\project\\urop-project\\face_recognition\\recognition_mosaic\\mtcnn\\mtcnn\n"
     ]
    }
   ],
   "source": [
    "cd C:\\project\\urop-project\\face_recognition\\recognition_mosaic\\mtcnn\\mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadfabdb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn-tflite in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (0.0.4)\n",
      "Requirement already satisfied: fcache>=0.4.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from mtcnn-tflite) (0.4.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from mtcnn-tflite) (1.19.5)\n",
      "Requirement already satisfied: opencv-python>=4.4 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from mtcnn-tflite) (4.5.2.52)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from mtcnn-tflite) (2.5.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from fcache>=0.4.0->mtcnn-tflite) (1.4.4)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (2.5.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (0.36.2)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.34.1)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.12)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (2.5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (3.17.3)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (3.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (0.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (0.12.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (3.7.4.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (3.3.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorflow>=2.0.0->mtcnn-tflite) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (1.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (57.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (1.26.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\skql7\\anaconda3\\envs\\test\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.0.0->mtcnn-tflite) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn-tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0558ea5",
   "metadata": {},
   "source": [
    "<h1> Collect images</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c75268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-0faa361c7a19>:15: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Face not Found\n",
      "Colleting Samples Complete!!!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import makedirs\n",
    "from os.path import isdir\n",
    "\n",
    "# 얼굴 저장 함수\n",
    "face_dirs = 'images/'\n",
    "face_classifier = cv2.CascadeClassifier('haar_face.xml')\n",
    "\n",
    "# 얼굴 검출 함수\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    # 얼굴이 없으면 패스!\n",
    "    if faces is():\n",
    "        return None\n",
    "    # 얼굴이 있으면 얼굴 부위만 이미지로 만들고\n",
    "    for(x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    # 리턴!\n",
    "    return cropped_face\n",
    "\n",
    "# 얼굴만 저장하는 함수\n",
    "def take_pictures(name):\n",
    "    # 해당 이름의 폴더가 없다면 생성\n",
    "    if not isdir(face_dirs+name):\n",
    "        makedirs(face_dirs+name)\n",
    "\n",
    "    # 카메라 ON    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        # 카메라로 부터 사진 한장 읽어 오기\n",
    "        ret, frame = cap.read()\n",
    "        # 사진에서 얼굴 검출 , 얼굴이 검출되었다면 \n",
    "        if face_extractor(frame) is not None:\n",
    "            \n",
    "            count+=1\n",
    "            # 200 x 200 사이즈로 줄이거나 늘린다음\n",
    "            face = cv2.resize(face_extractor(frame),(200,200))\n",
    "            # 흑백으로 바꿈\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 200x200 흑백 사진을 faces/얼굴 이름/userxx.jpg 로 저장\n",
    "            file_name_path = face_dirs + name + '/user'+str(count)+'.jpg'\n",
    "            cv2.imwrite(file_name_path,face)\n",
    "\n",
    "            cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow('Face Cropper',face)\n",
    "        else:\n",
    "            print(\"Face not Found\")\n",
    "            pass\n",
    "        \n",
    "        # 얼굴 사진 100장을 다 얻었거나 enter키 누르면 종료\n",
    "        if cv2.waitKey(1)==13 or count==300:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Colleting Samples Complete!!!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 사진 저장할 이름을 넣어서 함수 호출\n",
    "    take_pictures('Nagyung')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0c2b06",
   "metadata": {},
   "source": [
    "<h1>train</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca40642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10aba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cascade\n",
    "face_cascade = cv2.CascadeClassifier('haar_face.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a39b558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지금 내 코드 파일\n",
    "BASE_DIR = 'C:/project/urop-project/face_recognition/recognition_mosaic/mtcnn/mtcnn'\n",
    "# 이미지 경로\n",
    "image_dir = os.path.join(BASE_DIR, \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342e0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5a7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n",
      "{'nagyung': 0}\n"
     ]
    }
   ],
   "source": [
    "# 이미지 경로랑 이름, label 다 print\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(root).replace(\" \", \"-\").lower()\n",
    "            #print(label, path)\n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            print(label_ids)\n",
    "                \n",
    "            \n",
    "            # y_labels.append(label) # some number\n",
    "            # x_train.append(path) # verify this image, turn into a numpy array, GRAY\n",
    "            \n",
    "            pil_image = Image.open(path).convert(\"L\") #gray scale\n",
    "            size = (550, 550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(pil_image, \"uint8\")\n",
    "            #print(image_array)\n",
    "            faces = face_cascade.detectMultiScale(image_array, scaleFactor=1.5, minNeighbors=5)\n",
    "            \n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w] #roi에 얼굴 좌표 넣는다.\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "                \n",
    "#print(y_labels)\n",
    "#print(x_train)\n",
    "\n",
    "with open(\"labels.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "\n",
    "#Train OpenCV\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(\"trainner.yml\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb56ac",
   "metadata": {},
   "source": [
    "<h1>Face Detection</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d673a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1de84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cascade\n",
    "face_cascade = cv2.CascadeClassifier('haar_face.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model = recognizer.read(\"trainner.yml\")\n",
    "\n",
    "# 피클로 라벨이름 불러오기\n",
    "labels = {\"person_name\": 1}\n",
    "with open(\"labels.pickle\", 'rb') as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    # key value pairs\n",
    "    labels = {v:k for k,v in og_labels.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49c0fd",
   "metadata": {},
   "source": [
    "<h1>Recognition & Mosaic</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21992a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nagyung74\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "nagyung72\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "nagyung73\n",
      "0\n",
      "nagyung\n",
      "nagyung74\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "none:69\n",
      "none:26\n",
      "none:68\n",
      "none:68\n",
      "none:33\n",
      "none:68\n",
      "none:33\n",
      "none:30\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "nagyung75\n",
      "0\n",
      "nagyung\n",
      "none:64\n",
      "none:69\n",
      "none:64\n",
      "none:61\n",
      "none:66\n",
      "nagyung72\n",
      "0\n",
      "nagyung\n",
      "nagyung72\n",
      "0\n",
      "nagyung\n",
      "nagyung72\n",
      "0\n",
      "nagyung\n",
      "nagyung73\n",
      "0\n",
      "nagyung\n",
      "nagyung73\n",
      "0\n",
      "nagyung\n",
      "none:51\n",
      "nagyung74\n",
      "0\n",
      "nagyung\n"
     ]
    }
   ],
   "source": [
    "from mtcnn_tflite.MTCNN import MTCNN\n",
    "from math import sqrt\n",
    "detector = MTCNN()\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    min_score = 999  \n",
    "    #Use MTCNN to detect faces\n",
    "    faces = detector.detect_faces(frame)\n",
    "    if faces != []:\n",
    "        for person in faces:\n",
    "            bounding_box = person['box']\n",
    "            #for \n",
    "            \n",
    "#             print(\"faces:\" + str(faces))\n",
    "#             print(\"[0]: \" + str(bounding_box[0]))\n",
    "#             print(\"[1]: \" + str(bounding_box[1]))\n",
    "#             print(\"bounding box:\" + str(bounding_box))\n",
    "            x = bounding_box[0]\n",
    "            y = bounding_box[1]\n",
    "            w = bounding_box[2]\n",
    "            h = bounding_box[3]\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (0,155,255), 2)\n",
    "            #print(x,y,w,h)\n",
    "            #circle(frame, (x,y), 반지름, 색깔, thickness)\n",
    "            #conf = faces[0]['confidence']\n",
    "            #print(conf)\n",
    "            #implements recognizer 얼굴인식기 구현\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            id_, conf = recognizer.predict(roi_gray)\n",
    "            min_score = conf\n",
    "            if min_score < 500:\n",
    "                #????? 어쨋든 0~100표시하려고 한듯 \n",
    "                conf = int(100*(1-(min_score)/300))\n",
    "                if conf >= 70:\n",
    "                    print(labels[id_]+ str(conf))\n",
    "                    print(id_)\n",
    "                    print(labels[id_])\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    name = labels[id_]\n",
    "                    color = (255, 0, 0)\n",
    "                    stroke = 2\n",
    "                    display_string = str(int(conf))+'% '+ name\n",
    "                    cv2.putText(frame, display_string, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0),2, cv2.LINE_AA)\n",
    "                else:\n",
    "                    print(\"none:\" + str(conf))\n",
    "                    face_img = frame[y:y+h, x:x+w] # 인식된 얼굴 이미지 crop\n",
    "                    face_img = cv2.resize(face_img, dsize=(0, 0), fx=0.04, fy=0.04) # 축소\n",
    "                    face_img = cv2.resize(face_img, (w, h), interpolation=cv2.INTER_AREA) # 확대\n",
    "                    frame[y:y+h, x:x+w] = face_img # 인식된 얼굴 영역 모자이크 처리\n",
    "                    display_string = 'Stranger'\n",
    "                    cv2.putText(frame, display_string, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6833f876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\project\\\\urop-project\\\\face_recognition\\\\recognition_mosaic\\\\mtcnn\\\\mtcnn'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f23733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
